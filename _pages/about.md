---
permalink: /
title: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


Hello! I am currently a Ph.D. student at Thrust of Artificial Intelligence at [HKUST-GZ](https://www.hkust-gz.edu.cn/), under the supervision of Prof. [Menglin Yang](https://yangmenglinsite.github.io/). I obtained a Master's degree in Computer Science and Technology from the School of Artificial Intelligence at JLU, and a Bachelor's degree in Electronic Engineering from NUDT.

My research interests include Machine Learning (ML) and Deep Learning (DL), with a focus on:
- Large Language Models (LLMs)
  -  LLM Agent, Multi-Agent
  -  RAG, GraphRAG
  -  LLM Implicit Reasoning
  -  LLM Symbolic Reasoning
  -  others
- Multimodal Learning (MM), Vision-Language model (VLM)
- Electronic Design Automation (EDA) ***(Seeking Collaborators)***
- AI-Generated Content (AIGC)
- Geometric Learning with LLM, Geometric Foundation Model, Geometric Alignment
- Graph Learning (GNNs)
- Anomaly Detection (AD)
- Recommender System (RecSys)
- Domain Generalization (DG) and Domain Adaptation (DA)
- Unsupervised Learning, Few-Shot Learning
- Continual Learning (Incremental Learning)


## INFORMATION
- **E-mail**: [jli839@connect.hkust-gz.edu.cn](mailto:jli839@connect.hkust-gz.edu.cn)
- **WeChat**: alwaysbeakindperson &nbsp;&nbsp;*(means: always be a kind person)*
- **Google Scholar**: [![Google Scholar](https://img.shields.io/badge/scholar-4385FE.svg?&style=plastic&logo=google-scholar&logoColor=white)](https://scholar.google.com/citations?user=w-ZGDjMAAAAJ&hl=zh-CN) <font color="#FFA500">164</font>
- **GitHub**: [![GitHub](https://img.shields.io/badge/GitHub-181717?style=flat&logo=github&logoColor=white)](https://github.com/jindongli-Ai)




## TECHNICAL ACCOUNTS

Kaggle: [HomePage](https://www.kaggle.com/ac123321) | LeetCode1: [HomePage](https://leetcode.cn/u/xinghe_xinghe/) | LeetCode2: [HomePage](https://leetcode.cn/u/hanxin_hanxin/) | Acwing: [HomePage](https://www.acwing.com/user/myspace/record/94000/)
---|---|---|---
NowCoder: [HomePage](https://www.nowcoder.com/users/116877070) | CodeForces: [HomePage](https://codeforces.com/profile/XingHe_XingHe) | CSDN: [HomePage](https://blog.csdn.net/weixin_46645827?spm=1000.2115.3001.5343)

<div style="display: flex; align-items: center; gap: 15px; margin-bottom: 20px;">
  <img src="/images/kaggle.png" alt="Kaggle" width="50%">
  <img src="/images/leetcode-2.png" alt="LeetCode" width="27%">
</div>

<div style="display: flex; align-items: center; gap: 15px; margin-bottom: 20px;">
  <img src="/images/leetcode.png" alt="LeetCode" width="55%">
  <img src="/images/leetcode-2-1.png" alt="LeetCode" width="18%">
</div>



## PAPERS
*(\*: co-first author, \+: corresponding author)*

### Published

<div style="display: flex; align-items: center; gap: 15px;margin-bottom: 20px;">
  <img src="/images/CVTGAD.png" alt="CVTGAD" width="250">
  <div>
    [1] <b style="color: #0A1624;">CVTGAD: Simplified Transformer with Cross-View Attention for Unsupervised Graph-Level Anomaly Detection</b><br>
    <b>Jindong Li</b>, Qianli Xing, Qi Wang+, Yi Chang.<br>
    <i>European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD, CCF-B), 2023.</i><br>
    <a href="https://arxiv.org/abs/2405.02359">arXiv</a> | <a href="https://github.com/jindongli-Ai/CVTGAD">GitHub</a> 
  </div>
</div>


<div style="display: flex; align-items: center; gap: 15px;margin-bottom: 20px;">
  <img src="/images/ScreenAgent.png" alt="ScreenAgent" width="250">
  <div>
    [2] <b style="color: #0A1624;">ScreenAgent: A Vision Language Model-driven Computer Control Agent</b><br>
    Runliang Niu, <b>Jindong Li</b>, Shiqi Wang, Yali Fu, Xiyu Hu, Xueyuan Leng, He Kong, Yi Chang, Qi Wang+.<br>
    <i>International Joint Conference on Artificial Intelligence (IJCAI, CCF-A), 2024.</i><br>
    <a href="https://arxiv.org/abs/2402.07945">arXiv</a> | <a href="https://github.com/niuzaisheng/ScreenAgent">GitHub</a> | <a href="https://mp.weixin.qq.com/s/MNsRNr40vDqXdvoQ1_R-4Q">机器之心</a>
  </div>
</div>


<div style="display: flex; align-items: center; gap: 15px;margin-bottom: 20px;">
  <img src="/images/LCD-Net.png" alt="LCD-Net" width="250">
  <div>
    [3] <b style="color: #0A1624;">LCD-Net: A Lightweight Remote Sensing Change Detection Network Combining Feature Fusion and Gating Mechanism</b><br>
    Wenyu Liu, <b>Jindong Li</b>, Haoji Wang, Run Tan, Yali Fu, Qichuan Tian+<br>
    <i>IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing. (J-STAR, JCR Q1), 2025.</i><br>
    <a href="https://ieeexplore.ieee.org/document/10897814">IEEE</a> | <a href="https://github.com/WenyuLiu6/LCD-Net">GitHub</a> 
  </div>
</div>

<div style="display: flex; align-items: center; gap: 15px;margin-bottom: 20px;">
  <img src="/images/GLADMamba.png" alt="GLADMamba" width="250">
  <div>
    [4] <b style="color: #0A1624;">GLADMamba: Unsupervised Graph-Level Anomaly Detection Powered by Selective State Space Model</b><br>
    Yali Fu*, <b>Jindong Li*</b>, Qi Wang+, Qianli Xing.<br>
    <i>European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD, CCF-B), 2025.</i><br>
    <a href="https://arxiv.org/abs/2503.17903">arXiv</a> | <a href="https://github.com/Yali-F/GLADMamba">GitHub</a>
  </div>
</div>


<div style="display: flex; align-items: center; gap: 15px;margin-bottom: 20px;">
  <img src="/images/CLIPXpert.png" alt="CLIPXpert" width="250">
  <div>
    [5] <b style="color: #0A1624;">Beyond Retraining: Training-Free Unknown Class Filtering for Source-Free Open Set Domain Adaptation of Vision–Language Models.
</b><br>
    Yongguang Li, <b>Jindong Li</b>, Qi Wang+, Qianli Xing, Runliang Niu, Shengsheng Wang, Menglin Yang.<br>
    <i>Association for the Advancement of Artificial Intelligence Conference (AAAI, CCF-A), 2026.</i><br>
    <a href="https://arxiv.org/abs/2504.14224">arXiv</a>
  </div>
</div>


### arXiv Preprint

<div style="display: flex; align-items: center; gap: 15px;margin-bottom: 20px;">
  <img src="/images/LLM-Discrete-Tokenization-Survey.png" alt="LLM-Discrete-Tokenization-Survey" width="250">
  <div>
    [1] <b style="color: #0A1624;">Discrete Tokenization for Multimodal LLMs: A Comprehensive Survey</b><br>
    <b>Jindong Li*</b>, Yali Fu*, Jiahong Liu, Linxiao Cao, Wei Ji, Menglin Yang+, Irwin King, Ming-Hsuan Yang.<br>
    <i>arXiv Preprint.</i><br>
    <a href="https://arxiv.org/abs/2507.22920">arXiv</a> | 
    <a href="https://github.com/jindongli-Ai/LLM-Discrete-Tokenization-Survey">GitHub</a> |
    <a href="https://mp.weixin.qq.com/s/rDlzbRSEmQqBg-GRP0DTlA">机器之心</a> |
    <img src="https://img.shields.io/github/stars/jindongli-Ai/LLM-Discrete-Tokenization-Survey?color=yellow" alt="GitHub Stars" style="vertical-align: middle;"> 
    <img src="https://img.shields.io/github/forks/jindongli-Ai/LLM-Discrete-Tokenization-Survey?color=lightblue" alt="GitHub Forks" style="vertical-align: middle;">
  </div>
</div>




<div style="display: flex; align-items: center; gap: 15px;margin-bottom: 20px;">
  <img src="/images/LLM-Implicit-Reasoning-Survey.png" alt="LLM-Implicit-Reasoning-Survey" width="250">
  <div>
    [2] <b style="color: #0A1624;">Implicit Reasoning in Large Language Models: A Comprehensive Survey</b><br>
    <b>Jindong Li*</b>, Yali Fu*, Li Fan, Jiahong Liu, Yao Shu, Chengwei Qin, Menglin Yang+, Irwin King, Rex Ying.<br>
    <i>arXiv Preprint.</i><br>
    <a href="https://arxiv.org/abs/2509.02350">arXiv</a> | 
    <a href="https://github.com/digailab/awesome-llm-implicit-reasoning">GitHub</a> |
    <a href="https://mp.weixin.qq.com/s/YPVtFIFuEDW90CMfKaup_w">PaperWeekly</a> |
    <img src="https://img.shields.io/github/stars/digailab/awesome-llm-implicit-reasoning?color=yellow" alt="GitHub Stars" style="vertical-align: middle;"> 
    <img src="https://img.shields.io/github/forks/digailab/awesome-llm-implicit-reasoning?color=lightblue" alt="GitHub Forks" style="vertical-align: middle;">
  </div>
</div>



<div style="display: flex; align-items: center; gap: 15px;margin-bottom: 20px;">
  <img src="/images/LLM-RecSys-Survey.png" alt="LLM-RecSys-Survey" width="250">
  <div>
    [3] <b style="color: #0A1624;">Towards Next-Generation LLM-based Recommender Systems: A Survey and Beyond</b><br>
    Qi Wang*+, <b>Jindong Li*</b>, Shiqi Wang, Qianli Xing, Runliang Niu, He Kong, Rui Li, Guodong Long, Yi Chang, Chengqi Zhang.<br>
    <i>arXiv Preprint.</i><br>
    <a href="https://arxiv.org/abs/2410.19744">arXiv</a> | 
    <a href="https://github.com/jindongli-Ai/Next-Generation-LLM-based-Recommender-Systems-Survey">GitHub</a> | 
    <a href="https://mp.weixin.qq.com/s/2xM0Ax1P7ZprG5e6NL3WLA">机器学习与推荐算法</a> |
    <img src="https://img.shields.io/github/stars/jindongli-Ai/Next-Generation-LLM-based-Recommender-Systems-Survey?color=yellow" alt="GitHub Stars" style="vertical-align: middle;"> 
    <img src="https://img.shields.io/github/forks/jindongli-Ai/Next-Generation-LLM-based-Recommender-Systems-Survey?color=lightblue" alt="GitHub Forks" style="vertical-align: middle;">
  </div>
</div>



<div style="display: flex; align-items: center; gap: 15px;margin-bottom: 20px;">
  <img src="/images/CLIP-DG-DA-Survey.png" alt="CLIP-DG-DA-Survey" width="250">
  <div>
    [4] <b style="color: #0A1624;">CLIP-Powered Domain Generalization and Domain Adaptation: A Comprehensive Survey</b><br>
    <b>Jindong Li</b>, Yongguang Li, Yali Fu, Jiahong Liu, Yixin Liu, Menglin Yang+, Irwin King.<br>
    <i>arXiv Preprint.</i><br>
    <a href="https://arxiv.org/abs/2504.14280">arXiv</a> | 
    <a href="https://github.com/jindongli-Ai/Survey_of_CLIP-Powered_Domain_Generalization_and_Adaptation">GitHub</a> |
    <a href="https://www.jiqizhixin.com/articles/2025-05-06-5">机器之心</a> |
    <img src="https://img.shields.io/github/stars/jindongli-Ai/Survey_on_CLIP-Powered_Domain_Generalization_and_Adaptation?color=yellow" alt="GitHub Stars" style="vertical-align: middle;">
    <img src="https://img.shields.io/github/forks/jindongli-Ai/Survey_on_CLIP-Powered_Domain_Generalization_and_Adaptation?color=lightblue" alt="GitHub Forks" style="vertical-align: middle;">
  </div>
</div>



<div style="display: flex; align-items: center; gap: 15px;margin-bottom: 20px;">
  <img src="/images/Cogito.png" alt="Cogito" width="250">
  <div>
    [5] <b style="color: #0A1624;">Cogito, ergo sum: A Neurobiologically-Inspired Cognition-Memory-Growth System for Code Generation</b><br>
    Yanlong Li, <b>Jindong Li</b>, Qi Wang+, Menglin Yang, He Kong, Shengsheng Wang.<br>
    <i>arXiv Preprint.</i><br>
    <a href="https://arxiv.org/abs/2501.18653">PDF</a> | <a href="https://github.com/doc0318/Cogito">CODE</a> | <a href="https://techxplore.com/news/2025-02-neuro-ai-framework-reverse-code.html">TechXplore</a>
  </div>
</div>


<div style="display: flex; align-items: center; gap: 15px;margin-bottom: 20px;">
  <img src="/images/CANNON.png" alt="CANNON" width="250">
  <div>
    [6] <b style="color: #0A1624;">No Fear of Representation Bias: Graph Contrastive Learning with Calibration and Fusion</b><br>
    <b>Jindong Li</b>, Yixin Liu, Qianli Xing, Qi Wang+.<br>
    <i>arXiv Preprint.</i><br>
    <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4774833">SSRN</a> | <a href="https://github.com/jindongli-Ai/CANNON">GitHub</a>
  </div>
</div>


<div style="display: flex; align-items: center; gap: 15px;margin-bottom: 20px;">
  <img src="/images/HC-GLAD.png" alt="HC-GLAD" width="250">
  <div>
    [7] <b style="color: #0A1624;">HC-GLAD: Dual Hyperbolic Contrastive Learning for Unsupervised Graph-Level Anomaly Detection</b><br>
    Yali Fu*, <b>Jindong Li*</b>, Jiahong Liu, Qianli Xing, Qi Wang+, Irwin King.<br>
    <i>arXiv Preprint.</i><br>
    <a href="https://arxiv.org/abs/2407.02057">arXiv</a> | <a href="https://github.com/Yali-F/HC-GLAD">GitHub</a>
  </div>
</div>



<div style="display: flex; align-items: center; gap: 15px;margin-bottom: 20px;">
  <img src="/images/FANFOLD.png" alt="FANFOLD" width="250">
  <div>
    [8] <b style="color: #0A1624;">FANFOLD: Graph Normalization Flows-driven Asymmetric Network for Unsupervised Graph-Level Anomaly Detection</b><br>
    Rui Cao*, Shijie Xue*, <b>Jindong Li*</b>, Qianli Xing, Qi Wang+, Yi Chang.<br>
    <i>arXiv Preprint.</i><br>
    <a href="https://arxiv.org/abs/2407.00383">arXiv</a> | <a href="https://github.com/Goldenhorns/FANFOLD">GitHub</a>
  </div>
</div>



<div style="display: flex; align-items: center; gap: 15px;margin-bottom: 20px;">
  <img src="/images/CDBN.png" alt="CDBN" width="250">
  <div>
    [9] <b style="color: #0A1624;">Data-Efficient CLIP-Powered Dual-Branch Networks for Source-Free Unsupervised Domain Adaptation</b><br>
    Yongguang Li*, Yueqi Cao*, <b>Jindong Li</b>, Qi Wang, Shengsheng Wang+.<br>
    <i>arXiv Preprint.</i><br>
    <a href="https://arxiv.org/abs/2410.15811">PDF</a> | <a href="https://github.com/ethanAiJLu/CDBN">CODE</a>
  </div>
</div>


<div style="display: flex; align-items: center; gap: 15px;margin-bottom: 20px;">
  <img src="/images/DIPR.png" alt="DIPR" width="250">
  <div>
    [10] <b style="color: #0A1624;">DIRP: Efficient Point Cloud Registration via Dynamic Iteration</b><br>
    Yang Ai, <b>Jindong Li</b>, Qiang Bai, Xi Yang+.<br>
    <i>arXiv Preprint.</i><br>
    <a href="https://arxiv.org/abs/2312.02877v2">arXiv</a> | <a href="https://github.com/Ruye-aa/DIPR">GitHub</a>
  </div>
</div>


<!--
[11] **DiffRSG: Rules-based Skip-GCN in Neural Latent Information Diffusion Network for Social Recommendation.** <br>
Rui Cao, **Jindong Li\***, He Kong, Qi Wang, Yi Chang. <br>
[[CODE]](https://github.com/jindongli-Ai/DiffRSG)
-->


### In Preparation


[1] **A Survey on LLM Symbolic Reasoning.** <br>
**Jindong Li\***, Yali Fu*, Yang Yang, Jiahong Liu, Hongce Zhang, Haoxuan Li, Yutao Yue, Mengling Yang+. 
[[GitHub]](https://github.com/jindongli-Ai/LLM-Symbolic-Reasoning-Survey)

<!--
[4] **A Multimodal Benchmark for PCB Placement and Routing.** <br>
**Jindong Li**, Mengling Yang*. 
-->

<!-- 3. **Jindong Li**, Yali Fu, Qi Wang. Harnessing Large Language Models (LLMs) for Climate Change and Weather Forecasting: A Survey. [[GITHUB]](https://github.com/jindongli-Ai/Survey_on_LLM_for_Climate_Change_and_Weather_Forecasting) -->
<!-- 4. **Jindong Li+**, Xiyu Hu+, Qi Wang\*. HyGROVE: HyperFormer and Generative-Contrastive Learning for Unsupervised Graph-Level Anomaly Detection. -->
   


## Academic Service
- Reviewer, International World Wide Web Conference (WWW)
- Reviewer, International Conference on Computer Vision (ICCV)
- Reviewer, Artificial Intelligence Journal (AIJ)
- Reviewer, International Conference on Learning Representations (ICLR)




## WORK EXPERIENCE

### 1. Shanghai Artificial Intelligence Laboratory (Shanghai AI Lab) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; *2023.09-2023.12*
- **Research Intern**
- Mentor: [Bin Wang](https://wangbindl.github.io/) and [Linke Ouyang](https://scholar.google.com/citations?user=rDaVSiAAAAAJ&hl=zh-CN)
- Topic: Multimodal Large Language Models (MLLMs), Data Engine
- Responsibilities:
  - Evaluation of MLLMs
  - Multimodal (OCR mainly) models/approaches

<!--
### 2. Jilin University &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; *2024.07-2024.11*
- **Research Assistant**
- Mentor: Yi Chang and Qi Wang
-->


## COMPETITION EXPERIENCE

| No | Competition | Award | Year |
|----|-------------|-------|------|
| 1  | NUDT Intelligent Automobile Race | First Prize (1st place) |  |
| 2  | Hunan Province Intelligent Automobile Race of College Students | Second Prize |  |
| 3  | NUDT Electronic Design Competition Quadcopter Autonomous Aircraft Group | Third Prize (2nd place) |  |
| 4  | “LanQiao Cup” Programming Competition Graduate Group | Jilin, First Prize (2nd place) |  |
| 5  | “LanQiao Cup” Programming Competition Graduate Group | National Finals, Second Prize (11th place) | 2022 |
| 6  | “LanQiao Cup” Programming Competition Graduate Group | Jilin, Second Prize (5th place) | 2023 |
| 7  | “LanQiao Cup” Programming Competition Graduate Group | Jilin, First Prize (3rd place) | 2024 |
| 8  | “LanQiao Cup” Programming Competition Graduate Group | National Finals, Second Prize (17th place) | 2024 |
| 9  | Kaggle | 1 Silver Medal, 3 Bronze Medals |  |
| 10 | LeetCode | Contest Rating top 1% |  |


<div style="display: flex; align-items: center; gap: 15px; margin-bottom: 20px;">
  <img src="/images/Car.jpg" alt="Car" width="35%">
  <img src="/images/quadrotor.jpg" alt="Quadrotor" width="35%">
</div>

<div style="display: flex; align-items: center; gap: 15px; margin-bottom: 20px;">
  <img src="/images/蓝桥杯省一2022.jpg" alt="蓝桥杯省一2022" width="20%">
  <img src="/images/蓝桥杯国二2022.jpg" alt="蓝桥杯国二2022" width="20%">
  <img src="/images/蓝桥杯省二2023.jpg" alt="蓝桥杯省二2023" width="20%">
  <img src="/images/蓝桥杯省一2024.jpg" alt="蓝桥杯省一2024" width="20%">
  <img src="/images/蓝桥杯国二2024.jpg" alt="蓝桥杯国二2024" width="20%">
</div>






## HONORS AND AWARDS

| No | Institution | Award |
|----|-------------|-------|
| 1  | NUDT | Outstanding Student at the college level |
| 2  | NUDT | Outstanding Student at the university level |
| 3  | NUDT | Academic scholarship (student can only receive once during college) |
| 4  | NUDT | Outstanding Graduate at the college level |
| 5  | NUDT | Outstanding Graduate at the university level (0.2% in NUDT) |
| 6  | NUDT | Citation of Class Three Merit (三等功) |
| 7  | JLU | Academic scholarship |
| 8  | JLU | Academic scholarship |

## SKILLS

- **Language**: IELTS Overall Band Score 6.5 (Listening: 6.0, Reading: 7.0, Writing: 6.0, Speaking: 6.5) &nbsp;&nbsp;&nbsp; *2023.11*
- **Programming Languages**: Proficient in Python, C++, Java. Also experienced with C, Go, MySQL.
- **Deep Learning Tools**: PyTorch, TensorFlow


